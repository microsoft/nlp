{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Baseline Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a baseline model? \n",
    "\n",
    "Producing a baseline model is crucial for evaluating your model's performance on any machine learning problem. A baseline model is a basic solution to a machine learning problem that serves as a point of reference for comparing other models to. The baselines model's performance gives us an indication of how much better our models can perform relative to a naive approach. \n",
    "\n",
    "Let's say we are building a sentence similarity model where our training set contains pairs of sentences and we want to predict how similiar these sentences are on a scale from 1-5. We could spend months producing a complex machine learning solution to this problem and ultimately get a mean squared error (MSE) of 0.4. But is this result good or bad? There is no way of knowing without comparing it with some baseline performance. For our baseline model, we could predict the mean sentence similarity of sentence pairs in our training set (called the _zero rule_) and get a MSE of 0.2. So our model beats the baseline! If our model's performance was worse than the baseline, this might give us pause to consider using different features, models, evaluation metrics etc. It is crucial that the choice of baseline model be tailored to a data science problem based on buisness goals and the specific modeling task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are good baselines for sentence similarity?\n",
    "\n",
    "For sentence similarity problems, we have two sub-tasks: 1) First, we need to produce a representation of each sentence in the sentence pair. This representation is called an **embedding**.This embedding allows us to represent a sentence with numbers versus words. Specifically, we're learning an n-dimensional vector of numbers that can represent the given sentence. 2) Second, we need to compute the similarity between these two sentence embeddings.\n",
    "\n",
    "For producing representations of sentences, there are some common baseline approaches: \n",
    "1. Create word embeddings for each word in a sentence\n",
    "    1. word2vec word embeddings (word2vec)\n",
    "    2. GLoVe word embeddings (GLoVe)\n",
    "    \n",
    "2. Create sentence embeddings\n",
    "    1. doc2vec document embeddings (doc2vec)\n",
    "    2. TF-IDF embeddings (TF-IDF)\n",
    "\n",
    "Then we have to compare our embeddings to calculate sentence similarity:\n",
    "1. Word Embedding comparison\n",
    "    1. Cosine Similarity (first requires averaging the word embeddings of all words in each sentence)\n",
    "    2. Word Mover's Distance\n",
    "\n",
    "2. Sentence Embedding comparison\n",
    "    1. Cosine Similarity  \n",
    "    \n",
    "The different embedding models and similarity metrics are introduced and explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Data Loading and Preprocessing](#Data-Loading-and-Preprocessing)\n",
    "    * [Load STS Benchmark Dataset](#Load-STS-Benchmark-Dataset)\n",
    "    - [Preprocess / Tokenize](#Data-Preprocessing-/-Tokenization)\n",
    "    - [Document Frequency Calculation](#Document-Frequency-Calculation)\n",
    "* [Baseline Models](#Baseline-Models)\n",
    "    - [Baseline #1: word2vec and cosine similarity](#Baseline-#1:-word2vec-embeddings-+-cosine-similarity-(word2vec-+-cosine))\n",
    "    - [Baseline #2: word2vec and Word Mover's Distance](#Baseline-#2:-word2vec-embeddings-+-Word-Mover's-Distance-(word2vec-+-WMD))\n",
    "    - [Baseline #3: GloVe and cosine similarity](#Baseline-#3:-GloVe-embeddings-+-cosine-similarity-(GloVe-+-cosine))\n",
    "    * [Baseline #4: GloVe and Word Mover's Distance](#Baseline-#4:-GloVe-embeddings-+-Word-Mover's-Distance-(GloVe-+-WMD))\n",
    "    * [Baseline #5: Doc2vec and cosine similarity](#Baseline-#5:-Doc2vec-embeddings-+-cosine-similarity-(Doc2vec-+-cosine))\n",
    "    * [Baseline #6: TF-IDF and cosine similarity](#Baseline-#6:-TF-IDF-embeddings-+-cosine-similarity-(TF-IDF-+-cosine))\n",
    "* [Comparison of Baseline Models](#Comparison-of-Baseline-Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load STS Benchmark Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we utilize the [STS Benchmark dataset](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark#STS_benchmark_dataset_and_companion_dataset) which contains a selection of English datasets that were used in Semantic Textual Similarity (STS) tasks 2012-2017. The datasets include text from image captions, news headlines, and user forums. The dataset contains 8,628 sentence pairs with a human-labeled integer representing the sentences' similarity (ranging from 0 for no meaning overlap to 5 meaning equivalence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\") ## set the environment path\n",
    "BASE_DATA_PATH = \"../../data\"\n",
    "\n",
    "from utils_nlp.dataset.stsbenchmark import STSBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing this instance runs the downloader and extractor behind the scenes, then convert to dataframe\n",
    "stsTrain = STSBenchmark(\"train\", base_data_path=BASE_DATA_PATH).as_dataframe()\n",
    "stsTest = STSBenchmark(\"test\", base_data_path=BASE_DATA_PATH).as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5749 sentences\n",
      "Testing set has 1379 sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set has {len(stsTrain)} sentences\")\n",
    "print(f\"Testing set has {len(stsTest)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.500</td>\n",
       "      <td>A girl is styling her hair.</td>\n",
       "      <td>A girl is brushing her hair.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.600</td>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.000</td>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.200</td>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500</td>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.800</td>\n",
       "      <td>A woman is cutting onions.</td>\n",
       "      <td>A woman is cutting tofu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.500</td>\n",
       "      <td>A man is riding an electric bicycle.</td>\n",
       "      <td>A man is riding a bicycle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.200</td>\n",
       "      <td>A man is playing the drums.</td>\n",
       "      <td>A man is playing the guitar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.200</td>\n",
       "      <td>A man is playing guitar.</td>\n",
       "      <td>A lady is playing the guitar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.714</td>\n",
       "      <td>A man is playing a guitar.</td>\n",
       "      <td>A man is playing a trumpet.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0  2.500                    A girl is styling her hair.   \n",
       "1  3.600       A group of men play soccer on the beach.   \n",
       "2  5.000  One woman is measuring another woman's ankle.   \n",
       "3  4.200                A man is cutting up a cucumber.   \n",
       "4  1.500                       A man is playing a harp.   \n",
       "5  1.800                     A woman is cutting onions.   \n",
       "6  3.500           A man is riding an electric bicycle.   \n",
       "7  2.200                    A man is playing the drums.   \n",
       "8  2.200                       A man is playing guitar.   \n",
       "9  1.714                     A man is playing a guitar.   \n",
       "\n",
       "                                          sentence2  \n",
       "0                      A girl is brushing her hair.  \n",
       "1  A group of boys are playing soccer on the beach.  \n",
       "2           A woman measures another woman's ankle.  \n",
       "3                      A man is slicing a cucumber.  \n",
       "4                      A man is playing a keyboard.  \n",
       "5                          A woman is cutting tofu.  \n",
       "6                        A man is riding a bicycle.  \n",
       "7                      A man is playing the guitar.  \n",
       "8                     A lady is playing the guitar.  \n",
       "9                       A man is playing a trumpet.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsTest.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing / Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline models will expect that each sentence is represented by a list of **tokens**. Tokens are linguistic units like words, punctuation marks, numbers, etc. We'll use the nltk pacakge which is popular for performing tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from utils_nlp.dataset.preprocess import to_lowercase, to_spacy_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#run this cell if you haven't downloaded en_core_web_sm or hit an error on the below cell\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_low = to_lowercase(stsTest)\n",
    "sts_test = to_spacy_tokens(df_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sts_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also common to remove high-frequency words which do not help distinguish one sentence from another, so called **stop words**. For example, \"the\", \"and\", \"a\", etc. are typical stop words although each tokenization package may differ in the words they consider to be stop words. We'll tokenize our corpus without stop words so that we can compare our methods with and without stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return [t.lower() for t in nltk.word_tokenize(sentence)]\n",
    "\n",
    "def tokenize_no_stop_words(sentence):\n",
    "    return [t for t in sentence if t not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_test = stsTest\n",
    "sts_train = stsTrain\n",
    "\n",
    "sts_train['sentence1_tokens'] = sts_train['sentence1'].apply(tokenize)\n",
    "sts_train['sentence2_tokens'] = sts_train['sentence2'].apply(tokenize)\n",
    "\n",
    "sts_train['sentence1_tokens_no_stop'] = sts_train['sentence1_tokens'].apply(tokenize_no_stop_words)\n",
    "sts_train['sentence2_tokens_no_stop'] = sts_train['sentence2_tokens'].apply(tokenize_no_stop_words)\n",
    "\n",
    "\n",
    "sts_test['sentence1_tokens'] = sts_test['sentence1'].apply(tokenize)\n",
    "sts_test['sentence2_tokens'] = sts_test['sentence2'].apply(tokenize)\n",
    "\n",
    "sts_test['sentence1_tokens_no_stop'] = sts_test['sentence1_tokens'].apply(tokenize_no_stop_words)\n",
    "sts_test['sentence2_tokens_no_stop'] = sts_test['sentence2_tokens'].apply(tokenize_no_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each row in our dataframe contains the 2 original sentences as well as a column for each sentence's tokenization with stop words and a column for each sentence's tokenization without stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence1_tokens</th>\n",
       "      <th>sentence2_tokens</th>\n",
       "      <th>sentence1_tokens_no_stop</th>\n",
       "      <th>sentence2_tokens_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>A girl is styling her hair.</td>\n",
       "      <td>A girl is brushing her hair.</td>\n",
       "      <td>[a, girl, is, styling, her, hair, .]</td>\n",
       "      <td>[a, girl, is, brushing, her, hair, .]</td>\n",
       "      <td>[girl, styling, hair, .]</td>\n",
       "      <td>[girl, brushing, hair, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6</td>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "      <td>[a, group, of, men, play, soccer, on, the, bea...</td>\n",
       "      <td>[a, group, of, boys, are, playing, soccer, on,...</td>\n",
       "      <td>[group, men, play, soccer, beach, .]</td>\n",
       "      <td>[group, boys, playing, soccer, beach, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "      <td>[one, woman, is, measuring, another, woman, 's...</td>\n",
       "      <td>[a, woman, measures, another, woman, 's, ankle...</td>\n",
       "      <td>[one, woman, measuring, another, woman, 's, an...</td>\n",
       "      <td>[woman, measures, another, woman, 's, ankle, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.2</td>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "      <td>[a, man, is, cutting, up, a, cucumber, .]</td>\n",
       "      <td>[a, man, is, slicing, a, cucumber, .]</td>\n",
       "      <td>[man, cutting, cucumber, .]</td>\n",
       "      <td>[man, slicing, cucumber, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "      <td>[a, man, is, playing, a, harp, .]</td>\n",
       "      <td>[a, man, is, playing, a, keyboard, .]</td>\n",
       "      <td>[man, playing, harp, .]</td>\n",
       "      <td>[man, playing, keyboard, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0    2.5                    A girl is styling her hair.   \n",
       "1    3.6       A group of men play soccer on the beach.   \n",
       "2    5.0  One woman is measuring another woman's ankle.   \n",
       "3    4.2                A man is cutting up a cucumber.   \n",
       "4    1.5                       A man is playing a harp.   \n",
       "\n",
       "                                          sentence2  \\\n",
       "0                      A girl is brushing her hair.   \n",
       "1  A group of boys are playing soccer on the beach.   \n",
       "2           A woman measures another woman's ankle.   \n",
       "3                      A man is slicing a cucumber.   \n",
       "4                      A man is playing a keyboard.   \n",
       "\n",
       "                                    sentence1_tokens  \\\n",
       "0               [a, girl, is, styling, her, hair, .]   \n",
       "1  [a, group, of, men, play, soccer, on, the, bea...   \n",
       "2  [one, woman, is, measuring, another, woman, 's...   \n",
       "3          [a, man, is, cutting, up, a, cucumber, .]   \n",
       "4                  [a, man, is, playing, a, harp, .]   \n",
       "\n",
       "                                    sentence2_tokens  \\\n",
       "0              [a, girl, is, brushing, her, hair, .]   \n",
       "1  [a, group, of, boys, are, playing, soccer, on,...   \n",
       "2  [a, woman, measures, another, woman, 's, ankle...   \n",
       "3              [a, man, is, slicing, a, cucumber, .]   \n",
       "4              [a, man, is, playing, a, keyboard, .]   \n",
       "\n",
       "                            sentence1_tokens_no_stop  \\\n",
       "0                           [girl, styling, hair, .]   \n",
       "1               [group, men, play, soccer, beach, .]   \n",
       "2  [one, woman, measuring, another, woman, 's, an...   \n",
       "3                        [man, cutting, cucumber, .]   \n",
       "4                            [man, playing, harp, .]   \n",
       "\n",
       "                          sentence2_tokens_no_stop  \n",
       "0                        [girl, brushing, hair, .]  \n",
       "1         [group, boys, playing, soccer, beach, .]  \n",
       "2  [woman, measures, another, woman, 's, ankle, .]  \n",
       "3                      [man, slicing, cucumber, .]  \n",
       "4                      [man, playing, keyboard, .]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Frequency Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the baseline models we'll explore will require calculation of how frequently a word appears in the sentences of our corpus. In this preprocessing step, we iterate through the sentences in our training set, counting the number of sentences that contain each word. There are other ways to produce this calculation, including pulling larger datasets from the web and calculating the frequency on that data. For example, you could scrap data from Wikipedia or another text heavy site and calculate document frequencies on that corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_frequency(df):\n",
    "    document_frequency_dict = {}\n",
    "    sentences = df['sentence1'].append(df['sentence2']).apply(tokenize)\n",
    "    \n",
    "    for s in sentences:\n",
    "        for token in set(s):\n",
    "            if token in document_frequency_dict:\n",
    "                document_frequency_dict[token] += 1\n",
    "            else:\n",
    "                document_frequency_dict[token] = 1\n",
    "    return document_frequency_dict, len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequencies, num_documents = get_document_frequency(sts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11498"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline #1: word2vec embeddings + cosine similarity (word2vec + cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline constructs word embeddings using word2vec, constructs document embeddings by taking the average of the word embeddings, and then uses cosine similarity to measure sentence similarity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Word2Vec?\n",
    "Word2vec is a predictive model for learning word embeddings from text. Word embeddings are learned such that words that share common contexts in the corpus will be close together in the vector space. There are two different model architectures that can be used to produce word2vec embeddings: continuous bag-of-words (CBOW) or continuous skip-gram. The former uses a window of surrounding words (the \"context\") to predict the current word and the latter uses the current word to predict the surrounding context words. See this [tutorial](https://www.guru99.com/word-embedding-word2vec.html#3) on word2vec for more detailed background on the model.\n",
    "\n",
    "For our purposes, we use pretrained word2vec word embeddings. These embeddings were trained on a Google News corpus and provide 300-dimensional embeddings (vectors) for 3 million English words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Cosine Similarity?\n",
    "\n",
    "Cosine similarity is a typical similarity metric between vectors. Intuitively it measures the cosine of the angle between any two vectors. With vectors $a$ and $b$, the cosine similarity is: cosine_similarity($a$,$b$) = $\\frac{\\vec{a} \\cdot \\vec{b} }{||\\vec{a}|| ||\\vec{b}||}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "PATH_TO_WORD2VEC = os.path.expanduser(\"GoogleNews-vectors-negative300.bin\")\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_WORD2VEC, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def average_sentence_embedding(tokens, embedding_model):\n",
    "     #throw away tokens that are not in embeddings model\n",
    "    tokens = [i for i in tokens if i in embedding_model]\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "    \n",
    "    #We will weight by TF-IDF:\n",
    "    #For the TF part: # of times term appears / total terms in sentence\n",
    "    count = Counter(tokens)\n",
    "    token_list = list(count)\n",
    "    term_frequency = [count[i]/len(tokens) for i in token_list]\n",
    "    \n",
    "    #Now for the IDF part: LOG(# documents / # documents with term in it)\n",
    "    inv_doc_frequency = [math.log(num_documents/(document_frequencies.get(i, 0)+1)) for i in count]\n",
    "    \n",
    "    #Put the TF-IDF together and produce the weighted average of vector embeddings\n",
    "    word_embeddings = [embedding_model[token] for token in token_list]\n",
    "    weights = [term_frequency[i]*inv_doc_frequency[i] for i in range(len(token_list))]\n",
    "    return list(np.average(word_embeddings, weights = weights, axis = 0))\n",
    "    \n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    #distance.cosine calculates cosine DISTANCE, so take 1 - distance to get cosine similarity\n",
    "    cosine_similarity = 1 - distance.cosine(embedding1, embedding2) \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_average_cosine_similarity(df, embedding_model, stop_words=True):\n",
    "    predictions = []\n",
    "    if stop_words:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens'], df['sentence2_tokens'])\n",
    "    else:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens_no_stop'], df['sentence2_tokens_no_stop'])\n",
    "    \n",
    "    for (sentence1, sentence2) in tokenized_sentences:\n",
    "        embedding1 = average_sentence_embedding(sentence1, embedding_model)\n",
    "        embedding2 = average_sentence_embedding(sentence2, embedding_model)\n",
    "        if embedding1 == [] or embedding2 == []:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(calculate_cosine_similarity(embedding1, embedding2))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline #2: word2vec embeddings + Word Mover's Distance (word2vec + WMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline constructs word embeddings using word2vec and then uses the word mover's distance to measure sentence similarity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction to word2vec, see [Background on Word2Vec](#What-is-Word2Vec?)\n",
    "\n",
    "### What is Word Mover's Distance (WMD)?\n",
    "Word Mover's Distance (WMD) is a metric that \"adapts the earth mover’s distance to the space of documents: the distance between two texts is given by the total amount of “mass” needed to move the words from one side into the other, multiplied by the distance the words need to move.\" See this [blog](http://vene.ro/blog/word-movers-distance-in-python.html) for additional information about this similarity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(tokens, embedding_model):\n",
    "     #throw away tokens that are not in embeddings model\n",
    "    tokens = [i for i in tokens if i in embedding_model]\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "    \n",
    "    count = Counter(tokens)\n",
    "    token_list = list(count)\n",
    "    word_embeddings = [list(embedding_model[token]) for token in token_list]\n",
    "    return word_embeddings\n",
    "\n",
    "\n",
    "def word2vec_WMD(df, embedding_model, stop_words=True):\n",
    "    predictions = []\n",
    "    if stop_words:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens'], df['sentence2_tokens'])\n",
    "    else:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens_no_stop'], df['sentence2_tokens_no_stop'])\n",
    "    \n",
    "    for (sentence1, sentence2) in tokenized_sentences:\n",
    "        #throw away tokens that are not in embeddings model\n",
    "        tokens1 = [i for i in sentence1 if i in embedding_model]\n",
    "        tokens2 = [i for i in sentence2 if i in embedding_model]\n",
    "        if tokens1 == [] or tokens2 == []:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(-embedding_model.wmdistance(tokens1, tokens2))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline #3: GloVe embeddings + cosine similarity (GloVe + cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline constructs word embeddings using GloVE, constructs document embeddings by taking the average of the word embeddings, and then uses cosine similarity to measure sentence similarity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is GloVe?\n",
    "GloVe is an unsupervised algorithm for obtaining word embeddings. Training occurs on word-word co-occurance statistics with the objective of learning word embeddings such that the dot product of two word's embeddings is equal to the word's probability of co-occurance. See this [tutorial](https://nlp.stanford.edu/projects/glove/) on GloVe for more detailed background on the model.\n",
    "\n",
    "For our purposes, we use pretrained GloVe word embeddings (glove.840B.300d.zip which can be downloaded from above link). These embeddings were trained on Common Crawl data and provide 300-dimensional embeddings (vectors) for 2.2 million English words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction to the cosine similarity metric, see [Background on Cosine Similarity](#What-is-Cosine-Similarity?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#we need to download the GLoVe file and convert it to word2vec format, this takes a bit of time\n",
    "PATH_TO_GLOVE = os.path.expanduser(\"glove.840B.300d.txt\")\n",
    "tmp_file = \"glove.840B.300d.w2v.txt\"\n",
    "glove2word2vec(PATH_TO_GLOVE, tmp_file)\n",
    "glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_average_cosine_similarity(df, embedding_model, stop_words=True):\n",
    "    predictions = []\n",
    "    if stop_words:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens'], df['sentence2_tokens'])\n",
    "    else:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens_no_stop'], df['sentence2_tokens_no_stop'])\n",
    "    \n",
    "    for (sentence1, sentence2) in tokenized_sentences:\n",
    "        embedding1 = average_sentence_embedding(sentence1, embedding_model)\n",
    "        embedding2 = average_sentence_embedding(sentence2, embedding_model)\n",
    "        if embedding1 == [] or embedding2 == []:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(calculate_cosine_similarity(embedding1, embedding2))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline #4: GloVe embeddings + Word Mover's Distance (GloVe + WMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline constructs word embeddings using GloVE and then uses the word mover's distance metric to calculate sentence similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction on GloVe, see [Background on GloVe](#What-is-GloVe?)\n",
    "\n",
    "For an introduction to WMD, see [Background on Word Mover's Distance](#What-is-Word-Mover's-Distance-(WMD)?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_WMD(df, embedding_model, stop_words=True):\n",
    "    predictions = []\n",
    "    if stop_words:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens'], df['sentence2_tokens'])\n",
    "    else:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens_no_stop'], df['sentence2_tokens_no_stop'])\n",
    "    \n",
    "    for (sentence1, sentence2) in tokenized_sentences:\n",
    "        #throw away tokens that are not in embeddings model\n",
    "        tokens1 = [i for i in sentence1 if i in embedding_model]\n",
    "        tokens2 = [i for i in sentence2 if i in embedding_model]\n",
    "        if tokens1 == [] or tokens2 == []:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(-embedding_model.wmdistance(tokens1, tokens2))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline #5: Doc2vec embeddings + cosine similarity (Doc2vec + cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline constructs document embeddings using doc2vec and then applies cosine similarity to measure each sentence pair's similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Doc2Vec?\n",
    "\n",
    "Doc2vec is an extension of word2vec which produces embeddings of a document. Note that \"document\" refers to some larger chunk of multiple tokens/words. In our case, our documents will actually be individual setntences. The algorithm not only exploits the idea of context words (like in word2vec), but also incorporates the context of the document. There are again two model architectures that parallel those of word2vec, Paragraph Vectors Distributed Memory (PV-DM) and Paragraph Vectors Distributed Bag-of-Words (PV-DBOW). PV-DM randomly samples consecutive words in a paragraph and predicts a center word by utilizing the context words and the paragraph id. PV-DBOW takes a paragraph id and uses it to predict words in the context. \n",
    "\n",
    "See [tutorial #1](https://kanoki.org/2019/03/07/sentence-similarity-in-python-using-doc2vec/) or [tutorial #2](https://gab41.lab41.org/doc2vec-to-assess-semantic-similarity-in-source-code-667acb3e62d7) for more information and an example of using Doc2vec for sentence similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction to the cosine similarity metric, see [Background on Cosine Similarity](#What-is-Cosine-Similarity?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec requires unique ids for each sentence, so we'll iterate through making a dictionary of sentence to its id\n",
    "id_dict = {}\n",
    "n = 0\n",
    "\n",
    "def assign_id(row):\n",
    "    global n\n",
    "    if row not in id_dict:\n",
    "        id_dict[row] = n\n",
    "        n += 1\n",
    "    return id_dict[row]\n",
    "\n",
    "sts_test['qid1'] = sts_test['sentence1'].apply(assign_id)\n",
    "sts_test['qid2'] = sts_test['sentence2'].apply(assign_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "def doc2vec_cosine(df, stop_words=True):\n",
    "    predictions = []\n",
    "    if stop_words:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens'], df['sentence2_tokens'])\n",
    "    else:\n",
    "        tokenized_sentences = zip(df['sentence1_tokens_no_stop'], df['sentence2_tokens_no_stop'])\n",
    "        \n",
    "    labeled_questions=[]\n",
    "    sentences = list(tokenized_sentences)\n",
    "    for i in df.index:\n",
    "        labeled_questions.append(TaggedDocument(sentences[i][0], df[df.index == i].qid1))\n",
    "        labeled_questions.append(TaggedDocument(sentences[i][1], df[df.index == i].qid2))\n",
    "\n",
    "    model = Doc2Vec(labeled_questions, dm = 1, min_count=1, window=5, vector_size=500, epochs=30)\n",
    "        \n",
    "    for epoch in range(20):\n",
    "        model.train(labeled_questions,epochs=model.epochs,total_examples=model.corpus_count)\n",
    "    \n",
    "    for (sentence1, sentence2) in sentences:\n",
    "        if len(sentence1) == 0 or len(sentence2) == 0:\n",
    "            predictions.append(0)\n",
    "            continue\n",
    "        score = model.wv.n_similarity(sentence1,sentence2)\n",
    "        predictions.append(score)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline #6: TF-IDF embeddings + cosine similarity (TF-IDF + cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline constructs a document embedding based on bag of words with TF-IDF weighting and then applies cosine similarity between the two embeddings in the sentence pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TF-IDF?\n",
    "\n",
    "TF-IDF is a weighting scheme intended to measure how important a word is to the document (or sentence in our case) within the broader corpus (our dataset). The most basic approach for document embeddings is called Bag-of-Words. This method requires first determining the vocabulary across the entire corpus and then, for each document, creating a vector containing the number of times each vocabulary word appeared in the given document. These vectors are obviously very sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction to the cosine similarity metric, see [Background on Cosine Similarity](#What-is-Cosine-Similarity?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_cosine_similarity(df, stop_words = True):\n",
    "    if stop_words:\n",
    "        tf = TfidfVectorizer(input='content', analyzer='word', min_df = 0, stop_words = 'english', sublinear_tf=True)\n",
    "    else:\n",
    "        tf = TfidfVectorizer(input='content', analyzer='word', min_df = 0, stop_words = None, sublinear_tf=True)\n",
    "\n",
    "    all_sentences = list(df['sentence1'].append(df['sentence2']))\n",
    "    tfidf_matrix =  tf.fit_transform(all_sentences)\n",
    "    \n",
    "    n = 0\n",
    "    predictions = []\n",
    "    for (sentence1, sentence2) in zip(df['sentence1'], df['sentence2']):\n",
    "        sentence1_idx = n\n",
    "        sentence2_idx = len(sts_test['sentence1'])+n\n",
    "        sentence1_tfidf = list(tfidf_matrix.getrow(sentence1_idx).toarray()[0])\n",
    "        sentence2_tfidf = list(tfidf_matrix.getrow(sentence2_idx).toarray()[0])\n",
    "        if sum(sentence1_tfidf) == 0 or sum(sentence2_tfidf) == 0:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(calculate_cosine_similarity(sentence1_tfidf, sentence2_tfidf))\n",
    "        n += 1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation metric is Pearson correlation which is a measure of the linear correlation between two variables that takes a value in [-1,1] where -1 represents a perfect negative correlation, 1 represents a perfect positive correlation, and 0 represents no correlation. We utilize the Pearson correlation metric as this is the metric that [SentEval](http://nlpprogress.com/english/semantic_textual_similarity.html) , a widely-used evaluation toolkit for evaluation sentence representations, uses for the STS Benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def pearson_correlation(df, prediction):\n",
    "    pearson_correlation = scipy.stats.pearsonr(prediction, list(df['score']))[0]\n",
    "    return pearson_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_models = {\n",
    "    'Word2vec Cosine': word2vec_average_cosine_similarity(sts_test, word2vec, stop_words=False),\n",
    "    'Word2vec Cosine with Stop Words': word2vec_average_cosine_similarity(sts_test, word2vec, stop_words=True),\n",
    "    'Word2vec WMD' : word2vec_WMD(sts_test, word2vec, stop_words=False),\n",
    "    'Word2vec WMD with Stop Words' : word2vec_WMD(sts_test, word2vec, stop_words=True),\n",
    "    'GLoVe Cosine': glove_average_cosine_similarity(sts_test, glove, stop_words=False),\n",
    "    'GLoVe Cosine with Stop Words': glove_average_cosine_similarity(sts_test, glove, stop_words=True),\n",
    "    'GLoVe WMD' : glove_WMD(sts_test, glove, stop_words=False),\n",
    "    'GLoVe WMD with Stop Words' : glove_WMD(sts_test, glove, stop_words=True),\n",
    "    'Doc2vec Cosine': doc2vec_cosine(sts_test, stop_words=False),\n",
    "    'Doc2vec Cosine with Stop Words': doc2vec_cosine(sts_test, stop_words=True),\n",
    "    'TF-IDF Cosine': tfidf_cosine_similarity(sts_test, stop_words = False),\n",
    "    'TF-IDF Cosine with Stop Words': tfidf_cosine_similarity(sts_test, stop_words = True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec Cosine 0.6252265308481969\n",
      "Word2vec Cosine with Stop Words 0.6425244884199678\n",
      "Word2vec WMD 0.6434252846415083\n",
      "Word2vec WMD with Stop Words 0.5578145579252304\n",
      "GLoVe Cosine 0.6224951988473979\n",
      "GLoVe Cosine with Stop Words 0.5540268255219093\n",
      "GLoVe WMD 0.6198138203783634\n",
      "GLoVe WMD with Stop Words 0.4795588645934349\n",
      "Doc2vec Cosine 0.5174164747271393\n",
      "Doc2vec Cosine with Stop Words 0.3634126862348207\n",
      "TF-IDF Cosine 0.7034695168223283\n",
      "TF-IDF Cosine with Stop Words 0.6683811410442564\n"
     ]
    }
   ],
   "source": [
    "for model in baseline_models:\n",
    "    print(model, pearson_correlation(sts_test, baseline_models[model]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that TF-IDF bag-of-words document embeddings combined with the cosine similarity performs the best, with a Pearson correlation of 0.7034. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
