{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Text Classification of MultiNLI Sentences using XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils_nlp.dataset.multinli import load_pandas_df\n",
    "from utils_nlp.eval.classification import eval_classification\n",
    "from utils_nlp.common.timer import Timer\n",
    "from utils_nlp.models.xlnet.common import Language, Tokenizer\n",
    "from utils_nlp.models.xlnet.sequence_classification import XLNetSequenceClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we fine-tune and evaluate a pretrained [XLNet](https://arxiv.org/abs/1906.08237) model on a subset of the [MultiNLI](https://www.nyu.edu/projects/bowman/multinli/) dataset.\n",
    "\n",
    "We use a [sequence classifier](../../utils_nlp/xlnet/sequence_classification.py) that wraps [Hugging Face's PyTorch implementation](https://github.com/huggingface/pytorch-transformers) of CMU and Google's [XLNet](https://github.com/zihangdai/xlnet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../../../temp\"\n",
    "XLNET_CACHE_DIR=\"../../../temp\"\n",
    "LANGUAGE = Language.ENGLISHCASED\n",
    "MAX_SEQ_LENGTH = 128\n",
    "BATCH_SIZE = 8\n",
    "NUM_GPUS = 1\n",
    "NUM_EPOCHS = 3\n",
    "TRAIN_SIZE = 0.6\n",
    "LABEL_COL = \"genre\"\n",
    "TEXT_COL = \"sentence1\"\n",
    "\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.0\n",
    "ADAM_EPSILON = 1e-8\n",
    "WARMUP_STEPS = 0\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading a subset of the data. The following function also downloads and extracts the files, if they don't exist in the data folder.\n",
    "\n",
    "The MultiNLI dataset is mainly used for natural language inference (NLI) tasks, where the inputs are sentence pairs and the labels are entailment indicators. The sentence pairs are also classified into *genres* that allow for more coverage and better evaluation of NLI models.\n",
    "\n",
    "For our classification task, we use the first sentence only as the text input, and the corresponding genre as the label. We select the examples corresponding to one of the entailment labels (*neutral* in this case) to avoid duplicate rows, as the sentences are not unique, whereas the sentence pairs are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pandas_df(DATA_FOLDER, \"train\")\n",
    "df = df[df[\"gold_label\"]==\"neutral\"]  # get unique sentences\n",
    "\n",
    "if DEBUG:\n",
    "    inds = random.sample(range(len(df.index)), 100)\n",
    "    df = df.iloc[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>genre</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>promptID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>government</td>\n",
       "      <td>neutral</td>\n",
       "      <td>31193n</td>\n",
       "      <td>31193</td>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>( ( Conceptually ( cream skimming ) ) ( ( has ...</td>\n",
       "      <td>(ROOT (S (NP (JJ Conceptually) (NN cream) (NN ...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>( ( ( Product and ) geography ) ( ( are ( what...</td>\n",
       "      <td>(ROOT (S (NP (NN Product) (CC and) (NN geograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>telephone</td>\n",
       "      <td>neutral</td>\n",
       "      <td>50563n</td>\n",
       "      <td>50563</td>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>( yeah ( i ( ( tell you ) ( what ( ( though ( ...</td>\n",
       "      <td>(ROOT (S (VP (VB yeah) (S (NP (FW i)) (VP (VB ...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>( ( The ( tennis shoes ) ) ( ( have ( ( a rang...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN tennis) (NNS shoes))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>travel</td>\n",
       "      <td>neutral</td>\n",
       "      <td>42487n</td>\n",
       "      <td>42487</td>\n",
       "      <td>But a few Christian mosaics survive above the ...</td>\n",
       "      <td>( But ( ( a ( few ( Christian mosaics ) ) ) ( ...</td>\n",
       "      <td>(ROOT (S (CC But) (NP (DT a) (JJ few) (JJ Chri...</td>\n",
       "      <td>Most of the Christian mosaics were destroyed b...</td>\n",
       "      <td>( ( Most ( of ( the ( Christian mosaics ) ) ) ...</td>\n",
       "      <td>(ROOT (S (NP (NP (JJS Most)) (PP (IN of) (NP (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>slate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>32819n</td>\n",
       "      <td>32819</td>\n",
       "      <td>It's not that the questions they asked weren't...</td>\n",
       "      <td>( It ( ( ( ( 's not ) ( that ( ( ( the questio...</td>\n",
       "      <td>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (RB not) (...</td>\n",
       "      <td>All of the questions were interesting accordin...</td>\n",
       "      <td>( ( All ( of ( the questions ) ) ) ( ( ( were ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT All)) (PP (IN of) (NP (DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>travel</td>\n",
       "      <td>neutral</td>\n",
       "      <td>52772n</td>\n",
       "      <td>52772</td>\n",
       "      <td>Thebes held onto power until the 12th Dynasty,...</td>\n",
       "      <td>( Thebes ( ( ( ( ( held ( onto power ) ) ( unt...</td>\n",
       "      <td>(ROOT (S (NP (NNS Thebes)) (VP (VBD held) (PP ...</td>\n",
       "      <td>The capital near Memphis lasted only half a ce...</td>\n",
       "      <td>( ( ( The capital ) ( near Memphis ) ) ( ( ( (...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT The) (NN capital)) (PP (I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotator_labels       genre gold_label  pairID  promptID  \\\n",
       "0         [neutral]  government    neutral  31193n     31193   \n",
       "4         [neutral]   telephone    neutral  50563n     50563   \n",
       "6         [neutral]      travel    neutral  42487n     42487   \n",
       "12        [neutral]       slate    neutral  32819n     32819   \n",
       "13        [neutral]      travel    neutral  52772n     52772   \n",
       "\n",
       "                                            sentence1  \\\n",
       "0   Conceptually cream skimming has two basic dime...   \n",
       "4   yeah i tell you what though if you go price so...   \n",
       "6   But a few Christian mosaics survive above the ...   \n",
       "12  It's not that the questions they asked weren't...   \n",
       "13  Thebes held onto power until the 12th Dynasty,...   \n",
       "\n",
       "                               sentence1_binary_parse  \\\n",
       "0   ( ( Conceptually ( cream skimming ) ) ( ( has ...   \n",
       "4   ( yeah ( i ( ( tell you ) ( what ( ( though ( ...   \n",
       "6   ( But ( ( a ( few ( Christian mosaics ) ) ) ( ...   \n",
       "12  ( It ( ( ( ( 's not ) ( that ( ( ( the questio...   \n",
       "13  ( Thebes ( ( ( ( ( held ( onto power ) ) ( unt...   \n",
       "\n",
       "                                      sentence1_parse  \\\n",
       "0   (ROOT (S (NP (JJ Conceptually) (NN cream) (NN ...   \n",
       "4   (ROOT (S (VP (VB yeah) (S (NP (FW i)) (VP (VB ...   \n",
       "6   (ROOT (S (CC But) (NP (DT a) (JJ few) (JJ Chri...   \n",
       "12  (ROOT (S (NP (PRP It)) (VP (VBZ 's) (RB not) (...   \n",
       "13  (ROOT (S (NP (NNS Thebes)) (VP (VBD held) (PP ...   \n",
       "\n",
       "                                            sentence2  \\\n",
       "0   Product and geography are what make cream skim...   \n",
       "4            The tennis shoes have a range of prices.   \n",
       "6   Most of the Christian mosaics were destroyed b...   \n",
       "12  All of the questions were interesting accordin...   \n",
       "13  The capital near Memphis lasted only half a ce...   \n",
       "\n",
       "                               sentence2_binary_parse  \\\n",
       "0   ( ( ( Product and ) geography ) ( ( are ( what...   \n",
       "4   ( ( The ( tennis shoes ) ) ( ( have ( ( a rang...   \n",
       "6   ( ( Most ( of ( the ( Christian mosaics ) ) ) ...   \n",
       "12  ( ( All ( of ( the questions ) ) ) ( ( ( were ...   \n",
       "13  ( ( ( The capital ) ( near Memphis ) ) ( ( ( (...   \n",
       "\n",
       "                                      sentence2_parse  \n",
       "0   (ROOT (S (NP (NN Product) (CC and) (NN geograp...  \n",
       "4   (ROOT (S (NP (DT The) (NN tennis) (NNS shoes))...  \n",
       "6   (ROOT (S (NP (NP (JJS Most)) (PP (IN of) (NP (...  \n",
       "12  (ROOT (S (NP (NP (DT All)) (PP (IN of) (NP (DT...  \n",
       "13  (ROOT (S (NP (NP (DT The) (NN capital)) (PP (I...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples in the dataset are grouped into 5 genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "telephone     27783\n",
       "government    25784\n",
       "travel        25783\n",
       "fiction       25782\n",
       "slate         25768\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[LABEL_COL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data for training and testing, and encode the class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "df_train, df_test = train_test_split(df, train_size = TRAIN_SIZE)\n",
    "\n",
    "# encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_train = label_encoder.fit_transform(df_train[LABEL_COL])\n",
    "labels_test = label_encoder.transform(df_test[LABEL_COL])\n",
    "label_list = label_encoder.classes_\n",
    "\n",
    "num_labels = len(np.unique(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 5\n",
      "Number of training examples: 78540\n",
      "Number of testing examples: 52360\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique labels: {}\".format(num_labels))\n",
    "print(\"Number of training examples: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of testing examples: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Preprocess\n",
    "Before training, we tokenize the text documents and convert them to lists of tokens. The following steps instantiate a XLNet tokenizer given the language, and tokenize the text of the training and testing sets.\n",
    "\n",
    "We perform the following preprocessing steps in the cell below:\n",
    "- Convert the tokens into token indices corresponding to the XLNet-base tokenizer's vocabulary\n",
    "- Add the special tokens [CLS] and [SEP] to mark the end of a sentence\n",
    "- Pad or truncate the token lists to the specified max length\n",
    "- Return id lists that indicate which word the tokens map to\n",
    "- Return mask lists that indicate paddings' positions\n",
    "- Return segment type id lists that indicates which segment each the tokens belongs to\n",
    "\n",
    "*See the pytorch-transformer [implementation](https://github.com/huggingface/pytorch-transformers/blob/master/examples/utils_glue.py) for more information on XLNet's input format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 798011/798011 [00:00<00:00, 31134083.02B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(LANGUAGE, cache_dir=XLNET_CACHE_DIR)\n",
    "\n",
    "train_input_ids, train_input_mask, train_segment_ids = tokenizer.preprocess_classification_tokens(list(df_train[TEXT_COL]), MAX_SEQ_LENGTH)\n",
    "test_input_ids, test_input_mask, test_segment_ids = tokenizer.preprocess_classification_tokens(list(df_test[TEXT_COL]), MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "Next, we create a sequence classifier that loads a pre-trained XLNet model, given the language and number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 641/641 [00:00<00:00, 317720.26B/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = XLNetSequenceClassifier(\n",
    "    language=LANGUAGE, num_labels=num_labels, cache_dir=XLNET_CACHE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "We train the classifier using the training examples. This involves fine-tuning the XLNet Transformer and learning a linear classification layer on top of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    classifier.fit(\n",
    "        token_ids=train_input_ids,\n",
    "        input_mask=train_input_mask,\n",
    "        token_type_ids=train_segment_ids,\n",
    "        labels=labels_train,    \n",
    "        num_gpus=NUM_GPUS,        \n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,    \n",
    "        verbose=True,\n",
    "    )    \n",
    "print(\"[Training time: {:.3f} hrs]\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "We score the test set using the trained classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(\n",
    "    token_ids=test_input_ids,\n",
    "    input_mask=test_input_mask,\n",
    "    token_type_ids=test_segment_ids,\n",
    "    num_gpus=NUM_GPUS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    probabilities=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "Finally, we compute the accuracy, precision, recall, and F1 metrics of the evaluation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels_test, preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_gpu_DSVM)",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
